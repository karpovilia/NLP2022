{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c89ba63bb964286b56b2127be03edee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7507be03ce14491a8ddea53552432e90",
              "IPY_MODEL_f4bf6b1567e247daa115fdddcf697742",
              "IPY_MODEL_6b70328b2cef44c6b53cc3c1c5682573"
            ],
            "layout": "IPY_MODEL_db98154756904bb7a0ca20545cf7d708"
          }
        },
        "7507be03ce14491a8ddea53552432e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6df164c876ad4f4899436f5e29d39a8f",
            "placeholder": "​",
            "style": "IPY_MODEL_a489afd6665d440c81a0bd196b8b5664",
            "value": "Downloading: 100%"
          }
        },
        "f4bf6b1567e247daa115fdddcf697742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b451734db5da484e9db173544287da69",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec4b05533b334d0aa83aca6e2c35b9b4",
            "value": 231508
          }
        },
        "6b70328b2cef44c6b53cc3c1c5682573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c84b07363dcf4171be8b932b46cb258b",
            "placeholder": "​",
            "style": "IPY_MODEL_6c440e7133394bb88e03d99d61e24c5d",
            "value": " 232k/232k [00:00&lt;00:00, 590kB/s]"
          }
        },
        "db98154756904bb7a0ca20545cf7d708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df164c876ad4f4899436f5e29d39a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a489afd6665d440c81a0bd196b8b5664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b451734db5da484e9db173544287da69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4b05533b334d0aa83aca6e2c35b9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c84b07363dcf4171be8b932b46cb258b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c440e7133394bb88e03d99d61e24c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a32523c740b342d4a7e72d927e32f6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f35d3b26ec14e0180468bf775b9d362",
              "IPY_MODEL_7c5277e67fae4406a3fe440c94d3ec8c",
              "IPY_MODEL_419cc619bee84e509116f89b2b783d6b"
            ],
            "layout": "IPY_MODEL_eff3e41682a140118e1916e454b751fc"
          }
        },
        "0f35d3b26ec14e0180468bf775b9d362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a888e9d1ec540f895feb98b7460c03d",
            "placeholder": "​",
            "style": "IPY_MODEL_644f408a0f4a4221b50d8c4e89790bb6",
            "value": "Downloading: 100%"
          }
        },
        "7c5277e67fae4406a3fe440c94d3ec8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0086891f9446d6802da9ab0dea791a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_948ddd796640470bb7f4f830770b2a30",
            "value": 28
          }
        },
        "419cc619bee84e509116f89b2b783d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c01e6441d484b43917a1a581dbc7c14",
            "placeholder": "​",
            "style": "IPY_MODEL_675313ef0ddf4396af6afd8622a5e85e",
            "value": " 28.0/28.0 [00:00&lt;00:00, 717B/s]"
          }
        },
        "eff3e41682a140118e1916e454b751fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a888e9d1ec540f895feb98b7460c03d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644f408a0f4a4221b50d8c4e89790bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b0086891f9446d6802da9ab0dea791a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948ddd796640470bb7f4f830770b2a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c01e6441d484b43917a1a581dbc7c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675313ef0ddf4396af6afd8622a5e85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d40049e6f7a4396886459124a0dd1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d09c370395234aaf8cee76443ccb6217",
              "IPY_MODEL_bb7899c36d5b4c718e30bb593cd382e9",
              "IPY_MODEL_79f60b8b67b5480183734c78003338c4"
            ],
            "layout": "IPY_MODEL_6b7c04f340174687a8e3fbe6ff927faf"
          }
        },
        "d09c370395234aaf8cee76443ccb6217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a973b66b05f64014aaea794416abdff7",
            "placeholder": "​",
            "style": "IPY_MODEL_72847f9be1394845b710caee43e9d1a8",
            "value": "Downloading: 100%"
          }
        },
        "bb7899c36d5b4c718e30bb593cd382e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21616030810746ec81010d91ee2a1f27",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_481d3143d92d497283a3abf8bb9cd759",
            "value": 570
          }
        },
        "79f60b8b67b5480183734c78003338c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_575007dc0d0e44bd8225a4fdf1742b35",
            "placeholder": "​",
            "style": "IPY_MODEL_c3641ae7944f4fbd855161cb4ff3e5cb",
            "value": " 570/570 [00:00&lt;00:00, 28.3kB/s]"
          }
        },
        "6b7c04f340174687a8e3fbe6ff927faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a973b66b05f64014aaea794416abdff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72847f9be1394845b710caee43e9d1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21616030810746ec81010d91ee2a1f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "481d3143d92d497283a3abf8bb9cd759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "575007dc0d0e44bd8225a4fdf1742b35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3641ae7944f4fbd855161cb4ff3e5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbed504c3155466086be0db9e8d91bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0caaf90f3cb4affa60c411eab818174",
              "IPY_MODEL_356bcca401dc4f918fd81e09e5427a07",
              "IPY_MODEL_6bbd2a30c79e46cb9a8ca564628c693f"
            ],
            "layout": "IPY_MODEL_29ff77ae7e384991aae21c5d7c788aeb"
          }
        },
        "c0caaf90f3cb4affa60c411eab818174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68bc1cd64c6d4e8cb6ccbc6ce1d97fea",
            "placeholder": "​",
            "style": "IPY_MODEL_8d34affb0dd0442ea84f010a39778c97",
            "value": "Downloading: 100%"
          }
        },
        "356bcca401dc4f918fd81e09e5427a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddc6eb1926444a838b46f2bb241d907b",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_269b4727b71340e1be9d6630d6a8e9d2",
            "value": 440473133
          }
        },
        "6bbd2a30c79e46cb9a8ca564628c693f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eda2671a8b64721b68d24e346a0312e",
            "placeholder": "​",
            "style": "IPY_MODEL_cfff25272be94315938489faff03aec3",
            "value": " 440M/440M [00:13&lt;00:00, 36.4MB/s]"
          }
        },
        "29ff77ae7e384991aae21c5d7c788aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68bc1cd64c6d4e8cb6ccbc6ce1d97fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d34affb0dd0442ea84f010a39778c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddc6eb1926444a838b46f2bb241d907b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "269b4727b71340e1be9d6630d6a8e9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eda2671a8b64721b68d24e346a0312e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfff25272be94315938489faff03aec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADkUGTqixRWo"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## 1.1. Using Colab GPU for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696e8721-d92e-45cd-a520-e3ad22d5139d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571071ec-1205-4c1d-839e-64cbfa6a468e"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## 1.2. Installing the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "\n",
        "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
        "\n",
        "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
        "\n",
        "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4720dce8-564f-4436-ca87-132ae9e8543a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxddqmruamSj"
      },
      "source": [
        "The code in this notebook is actually a simplified version of the [run_glue.py](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py) example script from huggingface.\n",
        "\n",
        "`run_glue.py` is a helpful utility which allows you to pick which GLUE benchmark task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Loading CoLA Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk"
      },
      "source": [
        "We'll use [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) dataset for single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect. It was first published in May of 2018, and is one of the tests included in the \"GLUE Benchmark\" on which models like BERT are competing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "## 2.1. Download & Extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZNVW6xd0T0X"
      },
      "source": [
        "We'll use the `wget` package to download the dataset to the Colab instance's file system. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pO03Ff1BjI"
      },
      "source": [
        "The dataset is hosted on GitHub in this repo: https://nyu-mll.github.io/CoLA/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc993ee-eeba-4045-b79e-38304fa25489"
      },
      "source": [
        "!wget 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-14 11:15:20--  https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
            "Resolving nyu-mll.github.io (nyu-mll.github.io)... 185.199.109.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to nyu-mll.github.io (nyu-mll.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255330 (249K) [application/zip]\n",
            "Saving to: ‘cola_public_1.1.zip’\n",
            "\n",
            "\rcola_public_1.1.zip   0%[                    ]       0  --.-KB/s               \rcola_public_1.1.zip 100%[===================>] 249.35K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-01-14 11:15:20 (23.7 MB/s) - ‘cola_public_1.1.zip’ saved [255330/255330]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mKctx-ll2FB"
      },
      "source": [
        "Unzip the dataset to the file system. You can browse the file system of the Colab instance in the sidebar on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda12b1e-8547-4e7e-e4fd-d579ba39ea2b"
      },
      "source": [
        "import os\n",
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeyVCXT31EZQ"
      },
      "source": [
        "We can see from the file names that both `tokenized` and `raw` versions of the data are available. \n",
        "\n",
        "We can't use the pre-tokenized version because, in order to apply the pre-trained BERT, we *must* use the tokenizer provided by the model. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "3e955f97-ccee-43a1-dbf5-2039a044b340"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "4770            ks08      1         NaN   \n",
              "2026           rhl07      1         NaN   \n",
              "6300            c_13      1         NaN   \n",
              "8464            ad03      0           *   \n",
              "7733            ad03      1         NaN   \n",
              "1327            r-67      1         NaN   \n",
              "3124            l-93      1         NaN   \n",
              "2898            l-93      0           *   \n",
              "848             bc01      1         NaN   \n",
              "4522            ks08      1         NaN   \n",
              "\n",
              "                                               sentence  \n",
              "4770                           Who will they recommend?  \n",
              "2026           Where did you send the bicycle? To Rome.  \n",
              "6300  Frank will eat an apple and Morgan will eat an...  \n",
              "8464     The consul's gift of himself to the gladiator.  \n",
              "7733                         Jason was killed by Medea.  \n",
              "1327  Please make yourself comfortable and I'll wash...  \n",
              "3124               Teresa bottle fed the baby soy milk.  \n",
              "2898                   I broke the twig and the branch.  \n",
              "848                     John is leaving but Mary's not.  \n",
              "4522                          They wouldn't leave soon.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-744efde0-9b27-4d63-a162-edde9dd80ded\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4770</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Who will they recommend?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026</th>\n",
              "      <td>rhl07</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Where did you send the bicycle? To Rome.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6300</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Frank will eat an apple and Morgan will eat an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8464</th>\n",
              "      <td>ad03</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>The consul's gift of himself to the gladiator.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7733</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jason was killed by Medea.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1327</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Please make yourself comfortable and I'll wash...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3124</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Teresa bottle fed the baby soy milk.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I broke the twig and the branch.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John is leaving but Mary's not.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4522</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They wouldn't leave soon.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-744efde0-9b27-4d63-a162-edde9dd80ded')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-744efde0-9b27-4d63-a162-edde9dd80ded button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-744efde0-9b27-4d63-a162-edde9dd80ded');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWzpPi92UAH"
      },
      "source": [
        "The two properties we actually care about are the the `sentence` and its `label`, which is referred to as the \"acceptibility judgment\" (0=unacceptable, 1=acceptable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_LpQfzCn9_o"
      },
      "source": [
        "Here are five sentences which are labeled as not grammatically acceptible. Note how much more difficult this task is than something like sentiment analysis!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5a8ec41e-312c-41af-b7a4-ce465dc5df75"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "8075  Peter is some disgruntled old pigs in those di...      0\n",
              "347                                   John wrote books.      0\n",
              "2550         Cheryl stood the books from Edna to Sarah.      0\n",
              "917   Although Mag doesn't eggplants, Sally eats cab...      0\n",
              "169   His expectations lower, the higher the stakes ...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5cd3370-fe06-4cd8-9a70-21335fd941c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8075</th>\n",
              "      <td>Peter is some disgruntled old pigs in those di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>John wrote books.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2550</th>\n",
              "      <td>Cheryl stood the books from Edna to Sarah.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>Although Mag doesn't eggplants, Sally eats cab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>His expectations lower, the higher the stakes ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5cd3370-fe06-4cd8-9a70-21335fd941c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5cd3370-fe06-4cd8-9a70-21335fd941c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5cd3370-fe06-4cd8-9a70-21335fd941c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "6c89ba63bb964286b56b2127be03edee",
            "7507be03ce14491a8ddea53552432e90",
            "f4bf6b1567e247daa115fdddcf697742",
            "6b70328b2cef44c6b53cc3c1c5682573",
            "db98154756904bb7a0ca20545cf7d708",
            "6df164c876ad4f4899436f5e29d39a8f",
            "a489afd6665d440c81a0bd196b8b5664",
            "b451734db5da484e9db173544287da69",
            "ec4b05533b334d0aa83aca6e2c35b9b4",
            "c84b07363dcf4171be8b932b46cb258b",
            "6c440e7133394bb88e03d99d61e24c5d",
            "a32523c740b342d4a7e72d927e32f6a9",
            "0f35d3b26ec14e0180468bf775b9d362",
            "7c5277e67fae4406a3fe440c94d3ec8c",
            "419cc619bee84e509116f89b2b783d6b",
            "eff3e41682a140118e1916e454b751fc",
            "2a888e9d1ec540f895feb98b7460c03d",
            "644f408a0f4a4221b50d8c4e89790bb6",
            "7b0086891f9446d6802da9ab0dea791a",
            "948ddd796640470bb7f4f830770b2a30",
            "0c01e6441d484b43917a1a581dbc7c14",
            "675313ef0ddf4396af6afd8622a5e85e",
            "8d40049e6f7a4396886459124a0dd1d9",
            "d09c370395234aaf8cee76443ccb6217",
            "bb7899c36d5b4c718e30bb593cd382e9",
            "79f60b8b67b5480183734c78003338c4",
            "6b7c04f340174687a8e3fbe6ff927faf",
            "a973b66b05f64014aaea794416abdff7",
            "72847f9be1394845b710caee43e9d1a8",
            "21616030810746ec81010d91ee2a1f27",
            "481d3143d92d497283a3abf8bb9cd759",
            "575007dc0d0e44bd8225a4fdf1742b35",
            "c3641ae7944f4fbd855161cb4ff3e5cb"
          ]
        },
        "outputId": "0f66fd22-c3fa-4394-d48d-5de57e575121"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c89ba63bb964286b56b2127be03edee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a32523c740b342d4a7e72d927e32f6a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d40049e6f7a4396886459124a0dd1d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d307dc-9102-4338-af27-57eb586f7bd9"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNIc4auFUdF"
      },
      "source": [
        "When we actually convert all of our sentences, we'll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately. \n",
        "\n",
        "Before we can do that, though, we need to talk about some of BERT's formatting requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKGCCh8izww"
      },
      "source": [
        "## 3.2. Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDcqNlvVhL5W"
      },
      "source": [
        "The above code left out a few required formatting steps that we'll look at here.\n",
        "\n",
        "*Side Note: The input format to BERT seems \"over-specified\" to me... We are required to give it a number of pieces of information which seem redundant, or like they could easily be inferred from the data without us explicity providing it. But it is what it is, and I suspect it will make more sense once I have a deeper understanding of the BERT internals.*\n",
        "\n",
        "We are required to:\n",
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6mceWWOjZnw"
      },
      "source": [
        "### Special Tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykk0P9JiKtVe"
      },
      "source": [
        "\n",
        "**`[SEP]`**\n",
        "\n",
        "At the end of every sentence, we need to append the special `[SEP]` token. \n",
        "\n",
        "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?). \n",
        "\n",
        "I am not certain yet why the token is still required when we have only single-sentence input, but it is!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86C9objaKu8f"
      },
      "source": [
        "**`[CLS]`**\n",
        "\n",
        "For classification tasks, we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
        "\n",
        "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output (but with the feature values changed, of course!).\n",
        "\n",
        "![Illustration of CLS token purpose](https://drive.google.com/uc?export=view&id=1ck4mvGkznVJfW3hv6GUqcdGepVTOx7HE)\n",
        "\n",
        "On the output of the final (12th) transformer, *only the first embedding (corresponding to the [CLS] token) is used by the classifier*.\n",
        "\n",
        ">  \"The first token of every sequence is always a special classification token (`[CLS]`). The final hidden state\n",
        "corresponding to this token is used as the aggregate sequence representation for classification\n",
        "tasks.\" (from the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n",
        "You might think to try some pooling strategy over the final embeddings, but this isn't necessary. Because BERT is trained to only use this [CLS] token for classification, we know that the model has been motivated to encode everything it needs for the classification step into that single 768-value embedding vector. It's already done the pooling for us!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u51v0kFxeteu"
      },
      "source": [
        "### Sentence Length & Attention Mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPNuwqZVK3T6"
      },
      "source": [
        "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
        "\n",
        "BERT has two constraints:\n",
        "1. All sentences must be padded or truncated to a single, fixed length.\n",
        "2. The maximum sentence length is 512 tokens.\n",
        "\n",
        "Padding is done with a special `[PAD]` token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1cb5xeqLu_5vPOgs3eRnail2Y00Fl2pCo\" width=\"600\">\n",
        "\n",
        "The \"Attention Mask\" is simply an array of 1s and 0s indicating which tokens are padding and which aren't (seems kind of redundant, doesn't it?!). This mask tells the \"Self-Attention\" mechanism in BERT not to incorporate these PAD tokens into its interpretation of the sentence.\n",
        "\n",
        "The maximum length does impact training and evaluation speed, however. \n",
        "For example, with a V100:\n",
        "\n",
        "`MAX_LEN = 128  -->  Training epochs take ~5:28 each`\n",
        "\n",
        "`MAX_LEN = 64   -->  Training epochs take ~2:57 each`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## 3.3. Tokenize Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U28qy4P-NwQ9"
      },
      "source": [
        "The transformers library provides a helpful `encode` function which will handle most of the parsing and data prep steps for us.\n",
        "\n",
        "Before we are ready to encode our text, though, we need to decide on a **maximum sentence length** for padding / truncating to.\n",
        "\n",
        "The below cell will perform one tokenization pass of the dataset in order to measure the maximum sentence length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5a0477-9be4-4724-af1e-24b76f19a21d"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M296yz577fV"
      },
      "source": [
        "Just in case there are some longer test sentences, I'll set the maximum length to 64.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWAoWL2RK1p"
      },
      "source": [
        "Now we're ready to perform the real tokenization.\n",
        "\n",
        "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
        "\n",
        "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285cf8af-4bea-4b64-8c06-f229889f26f6"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Attention masks:', attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 3.4. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2059abb-fbac-4ff0-acdb-1c540b8b47d2"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sjzRT1V0zwm"
      },
      "source": [
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
        "\n",
        "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
        "\n",
        "Here is the current list of classes provided for fine-tuning:\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* **BertForSequenceClassification** - The one we'll use.\n",
        "* BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
        "\n",
        "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bbed504c3155466086be0db9e8d91bd1",
            "c0caaf90f3cb4affa60c411eab818174",
            "356bcca401dc4f918fd81e09e5427a07",
            "6bbd2a30c79e46cb9a8ca564628c693f",
            "29ff77ae7e384991aae21c5d7c788aeb",
            "68bc1cd64c6d4e8cb6ccbc6ce1d97fea",
            "8d34affb0dd0442ea84f010a39778c97",
            "ddc6eb1926444a838b46f2bb241d907b",
            "269b4727b71340e1be9d6630d6a8e9d2",
            "6eda2671a8b64721b68d24e346a0312e",
            "cfff25272be94315938489faff03aec3"
          ]
        },
        "outputId": "72b51050-eb77-4642-b391-643d329b292d"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbed504c3155466086be0db9e8d91bd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402e2390-e15d-4a57-e08a-44669ec14f38"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b509151-3ca9-42e6-bb8a-b6a1b35323dc"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
        "\n",
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c277fbe-f6b5-447a-a1dc-ea39ba9fe50c"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # forward: https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # results: https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches to calculate the average loss at the end\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0 to help prevent the \"exploding gradients\" problem.\n",
        "        # https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters using update rule\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # Final accuracy for one validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:44.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.41\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.56\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:06:00 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5d37d1d6-c686-4402-da54-e3acb11dc096"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.50         0.43           0.82       0:01:26         0:00:03\n",
              "2               0.31         0.41           0.83       0:01:27         0:00:04\n",
              "3               0.20         0.51           0.85       0:01:27         0:00:03\n",
              "4               0.14         0.56           0.85       0:01:27         0:00:03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7ebefe0-997a-4943-923c-17cbde82b54f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:01:26</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:27</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:01:27</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:01:27</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7ebefe0-997a-4943-923c-17cbde82b54f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7ebefe0-997a-4943-923c-17cbde82b54f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7ebefe0-997a-4943-923c-17cbde82b54f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "cab2b1be-2a94-494b-96b6-4aaa7770f741"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DosV94BYIYxg"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### 5.1. Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e955ff-20e2-4d95-dc5b-6799e0f66a80"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## 5.2. Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5412724-db53-4302-a651-89c239fb7688"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57778df-cca0-4635-c514-8f2c3acc86e6"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf03cfb8-57cc-4a83-b001-4d4f67ef6821"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUM0UA1qJaVB"
      },
      "source": [
        "The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches. \n",
        "\n",
        "Each batch has 32 sentences in it, except the last batch which has only (516 % 32) = 4 test sentences in it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "1a36f902-1580-4b70-de49-fcc17f51ee54"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAGaCAYAAACCFszYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVzUdeLH8feAAyigoKGVCpmKeKHilaaZN5X3bSmZpV20ZQ9bdPvV7rptllHSeqza4YGWFxCppaa1WWpqZqKJhmYeUYoiKCgOwvz+cGWbgGHQGYZvvZ6PR49HfK/PewaPN18/8/marFarVQAAAAAMx8PdAQAAAABcH8o8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAMDgxo4dqx49erg7BgA3qOLuAADgLjt27FBUVJQk6YEHHtCLL75Y7JizZ8+qW7duys/PV4cOHRQfH1/smH379mnZsmXatWuXMjIy5OHhoXr16qlTp04aNWqUGjZsaHP8pUuXtGLFCm3cuFGHDx9Wbm6uatSooebNm+uee+7RgAEDVKWK/T+eL1y4oPj4eG3YsEE//fSTCgoKFBgYqLCwMHXv3l3Dhw+/gXcGv9WjRw/99NNPRV+bTCbVqlVLDRo00OjRo3Xfffdd97U3bdqk1NRUPfXUU86ICuAPhjIP4A/P29tba9eu1ZQpU+Tl5WWzLzk5WVartdRyPXv2bM2ePVuBgYHq16+fGjVqpMLCQh0+fFgff/yxli1bpp07d8rPz0+SdOzYMU2cOFE//vijOnfurIkTJyowMFBnz57V9u3bNXXqVB0+fFh//vOfS82bk5OjYcOG6cSJE+rbt6+GDh0qs9msEydO6JtvvtGSJUso8y5w880369lnn5UkFRYW6tSpU0pKStKzzz6rjIwMjRs37rquu2nTJiUlJVHmAVwXyjyAP7zevXtr7dq12rRpk+69916bfYmJibrrrrv01VdfFTtv9erVmjVrljp27Kg5c+bI39/fZv9zzz2n2bNnF32dl5enRx99VCdPntSsWbPUp08fm+MnTpyolJQU7du3z27elStX6scff9Rf/vIXPfjgg8X2Z2RklPmaXSEnJ6fohxYjsVqtunjxonx9fe0e5+/vr4EDB9psGzlypLp27arExMTrLvMAcCOYMw/gD69Zs2Zq0qSJEhMTbbanpKQoLS1NQ4cOLXaOxWJRXFycqlWrpri4uGJFXpJ8fHw0efLkooK7atUqHT16VA899FCxIn9NeHi4HnjgAbt5f/zxR0lSp06dStwfFBRUbNuxY8c0depU3XXXXWrRooW6dOmixx9/XPv377c5btOmTRo1apRat26tNm3aaNSoUdq0aVOx6/Xo0UNjx47VgQMH9PDDD6tt27YaMGCATcbnnntOXbp0UYsWLdSjRw+9+uqrunjxot3X9tvrf/fdd4qKilKbNm3UoUMHxcTE6OzZs8WOt1gsmjdvnu677z61bNlS7dq102OPPaYDBw7YHLdjx46i7/WyZct07733qmXLlnr33XcdyvVbNWrUkJeXl8xms832lJQUTZkyRX379lWrVq2K3stPPvnE5rixY8cqKSlJktSkSZOi/379azEjI0MvvfSSevbsqRYtWqhTp0566KGHtHXr1mJ5Tp06pWeffVbt27dXq1at9PDDD+vo0aPX9doAGAN35gFA0tChQ/XKK6/o1KlTqlOnjqSrd95r1aqlu+++u9jx33zzjTIyMjRw4EDVrFnToTE2bNgg6erd3BsRHBws6eq/GkyePLnM+fX79u3TuHHjdOXKFQ0bNkyNGzdWdna2du7cqT179qhFixaSpGXLlmnatGm6/fbb9cQTT0iSkpKS9OSTT2ratGnFcqenp+vBBx9UZGSk+vTpU1TU9+/frwcffFDVq1fXyJEjVadOHR08eFDx8fHas2eP4uPji5Xfkvzyyy8aN26c+vTpo759++rAgQNKSEjQ/v37tXr1alWtWlWSlJ+fr4cfflh79uzRwIED9cADDygnJ0crV67U6NGjtXTpUrVs2dLm2osXL1ZWVpaGDx+uoKAg3XzzzWXmKSgoUGZmpqSr02wyMjK0ZMkS5ebmatSoUTbHfvLJJ/rhhx8UGRmpunXrKisrS0lJSYqOjlZsbKz69+8vSXrsscdUWFior7/+WjNmzCg6PyIiQpJ08uRJjR49WmfPntXAgQPVokULXbp0SXv37tW2bdt05513Fp1z8eJFjRkzRq1atdKkSZN08uRJLVmyRE888YTWrl0rT0/PMl8jAAOyAsAf1FdffWUNDQ21vv3229bMzExr8+bNrf/+97+tVqvVeunSJWvbtm2tr7zyitVqtVpbt25tHTNmTNG5S5YssYaGhlrfffddh8fr0KGDNSIi4oZzZ2VlWbt162YNDQ21durUyfrUU09Z58+fb921a5e1oKDA5tjCwkLrfffdZ23RooU1NTW12LWuHZ+VlWVt3bq1tVevXtYLFy4U7b9w4YK1Z8+e1tatW1uzs7OLtnfv3t0aGhpqXblyZbFr9u/f39q3b1+b61itVuvGjRutoaGh1oSEhDJf47XrL1y40Gb7woULraGhodb58+cX27ZlyxabYy9cuGDt1q2bzfft2ve8ffv21jNnzpSZ47d5fvtfy5YtrcuXLy92fG5ubrFtFy9etPbp08d6zz332GyPiYmxhoaGljjuI488UuJrs1qtNt/rMWPGWENDQ60LFiywOeatt94q9XwAvw9MswEASYGBgerRo0fRlIeNGzfqwoULJU6xka7OD5dUrjniOTk5Zc7LdkSNGjWUmJioCRMmyN/fXxs2bNDrr7+uBx54QL169dKXX35ZdGxqaqrS0tI0ZMgQhYWFFbuWh8fVvwa2bt2qixcvauzYsTavyc/PT2PHjtXFixe1bds2m3MDAgI0ZMgQm22HDh3SoUOH1K9fP1ksFmVmZhb917ZtW1WrVq3E6SEl8fPz0/3332+z7f7775efn5/NdJUPP/xQt99+u5o3b24znsViUefOnbV7927l5eXZXGfgwIGqVauWQzmuqVu3rhYuXKiFCxfq3Xff1SuvvKJWrVrpb3/7mxISEmyOrVatWtH/X7p0SefOndOlS5d0xx136MiRI0W/fuzJysrSF198oa5du6pr167F9l/73v3662urM11zxx13SLo6zQrA7xPTbADgv4YOHaqJEyfq66+/VkJCgsLDw9WoUaMSj71WeHNzcx2+vp+fX7mOt6dmzZqaPHmyJk+erHPnzunbb7/Vxx9/rA8//FDR0dFKTk5WSEhI0fz6Zs2a2b3eyZMnJUmNGzcutu/athMnTthsr1+/frGpG0eOHJEkzZo1S7NmzSpxrDNnzpT9Av97/d+uLuTl5aX69evbZDly5Ijy8vJK/QyBJJ07d0633HJL0de33XabQxl+rVq1aurcubPNtv79+2vw4MF66aWX1KNHDwUGBkq6uqRpXFycNm/eXOIc//Pnz5f5g+Dx48dltVrL/N5dU7t2bXl7e9tsCwgIkHT1BwMAv0+UeQD4ry5duqhOnTqaM2eOduzYob/97W+lHnut4P72A5b2NG7cWLt27dKJEydUv379G41bJDAwUN27d1f37t11yy23aN68eVq3bl3RvHdXuTZnvSTjx48v8W6yJFWvXt2pOaxWq0JDQzV16tRSj/nt5xrsZS+PKlWq6I477tCSJUuUkpKibt26yWq1avz48Tpy5IiioqLUokUL+fv7y9PTUwkJCVq7dq0KCwudMv6v2ZsTb7VanT4egMqBMg8A/+Xp6alBgwZp/vz58vHxUb9+/Uo9NiIiQkFBQdq0aZPOnTtXdEfWnj59+mjXrl1atWpV0XrlztaqVStJV1c1kaQGDRpIujrdxp5rP1ykpaUVu8N9+PBhm2PsCQkJkXR1ysdv72KX14kTJ2SxWGzuzlssFp04cUK33367zZjnzp3THXfcUWzqSUW4cuWKpP/9K82hQ4d08OBBPfnkk/rTn/5kc+yqVauKnW8ymUq8bnBwsEwmU5nfOwB/bMyZB4BfGTVqlKKjo/X3v//d7jQILy8vPfPMM8rNzdWkSZNKnAN9+fJlvfHGG0X7hg8frgYNGujdd98tcblH6epKMMuWLbObcc+ePTp//nyJ+65d99r0oLCwMDVu3FgJCQlKS0srdvy1O7Z33nmnqlWrpqVLl9q8lpycHC1dulTVqlWzWTmlNM2aNVNoaKiWL19ebFqOdLX4OjrlIycnR++9957Ntvfee085OTnq1atX0bZBgwYpIyNDCxcuLPE6jk7ruR6XL1/WF198Iel/U5mu/UDx27vh33//fbGlKaX/za//7fsSEBCgu+66S1u2bCn2eYWSrg/gj4k78wDwK7feeqvDT+IcNmyYfvnlF82ePVt9+vSxeQLskSNHtH79emVmZmrixImSrk7tmD9/viZOnKgnn3xSXbp0UefOnRUQEKDMzEzt2LFDX375pR555BG7465Zs0aJiYnq1q2bwsPDFRAQoKysLH3++efasWOHGjVqVPTBXZPJpJdfflnjxo3T8OHDi5amPH/+vHbt2qWuXbtq7Nixql69uiZPnqxp06ZpxIgRGjx4sKSrS1MeO3ZM06ZNK3Et/d8ymUyaMWOGHnzwQQ0YMEBDhw5Vo0aNlJeXp2PHjumTTz7Rs88+W+yDsyUJDg7WnDlzlJaWpubNm+u7775TQkKCbr/9do0dO7bouKioKG3btk0zZszQV199pTvuuEN+fn5KT0/XV199JS8vL8XHx5c5XlkuXLig5ORkSVeL9OnTp7VmzRqdOHFCI0aMKJqH37BhQzVu3Fhvv/228vLy1KBBAx09elQrVqxQaGiovvvuO5vrtmrVSkuXLtXf//53devWTWazWeHh4apfv75eeOEFHThwQBMmTNCgQYPUvHlzXb58WXv37lXdunX13HPP3fDrAmBslHkAuAHR0dHq1q2bli5dqk2bNun999+Xh4eHgoODde+992r06NE2d/hDQkL0wQcfaMWKFdqwYYPmzZunixcvqkaNGmrRooVeeeWVojXISzNq1Cj5+/trx44dWrhwobKysmQ2mxUSEqLo6Gg99NBDNquphIeHa/Xq1Zo7d64+/vhjLV++XAEBAQoPDy9az1ySHnjgAdWuXVvvvPOO5syZI+nqnf05c+bY3AkvS9OmTZWUlKT58+fr008/1fLly+Xr66u6detq8ODBdj+o+ms333yz4uLi9Oqrr2rdunUym83q37+/YmJibF6f2WzW/Pnz9d577yk5Obnog7e1a9dWy5Yti34wuVG//PKL/vznPxd9XbVqVTVs2FB//etfbdaZ9/T01Pz58/Xqq68qKSlJly5dUuPGjfXqq6/q4MGDxcp8v379lJqaqnXr1mn9+vUqLCzU9OnTVb9+fdWvX18JCQmaM2eOtmzZouTkZFWvXl1hYWE3/LwCAL8PJiv/TgcAqGR69OihunXrOuWOOgD8njFnHgAAADAoyjwAAABgUJR5AAAAwKCYMw8AAAAYFHfmAQAAAIOizAMAAAAGxTrzN+jcuVwVFjJTCQAAAM7n4WFSYKBvqfsp8zeosNBKmQcAAIBbMM0GAAAAMCjKPAAAAGBQlHkAAADAoCjzAAAAgEFR5gEAAACDoswDAAAABkWZBwAAAAyKMg8AAAAYFGUeAAAAMCjKPAAAAGBQlHkAAADAoCjzAAAAgEFVcXcAAAD+KPwDqsrH7J6/evPyr+hC1iW3jA3AdSjzAABUEB9zFQ1O+MwtYycN7a4LbhkZgCsxzQYAAAAwKMo8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKMo8AAAAYFCUeQAAAMCgqrg7AAAAgD01AnzlZXbf/UdLfqGys3LdNj5gD2UeAABUal5mDy1IPO228ScOqe22sYGyMM0GAAAAMCjKPAAAAGBQlHkAAADAoCjzAAAAgEFR5gEAAACDoswDAAAABkWZBwAAAAyKMg8AAAAYFGUeAAAAMCjKPAAAAGBQlHkAAADAoCjzAAAAgEFR5gEAAACDMmSZt1gseu2119SlSxeFh4drxIgR2r59u0Pnbtu2TWPHjlXHjh3Vvn17jRw5Uh999JGLEwMAAADOZ8gyP2XKFC1evFgDBgzQ888/Lw8PD02YMEF79uyxe95nn32m8ePH68qVK3rqqaf09NNPy8PDQ5MmTdKqVasqKD0AAADgHFXcHaC8UlJStG7dOk2dOlXjxo2TJA0aNEj9+vVTbGysli1bVuq5y5YtU1BQkBYvXiwvLy9J0ogRI9SzZ08lJydr+PDhFfESAAAAAKcw3J359evXy2w22xRvb29vDRs2TLt379bp06dLPTcnJ0c1atQoKvKS5OXlpRo1asjb29uluQEAAABnM1yZT01NVYMGDeTr62uzPTw8XFarVampqaWe26FDB6WlpSkuLk7Hjx/X8ePHFRcXpx9//FHjx493dXQAAADAqQw3zSYjI0N16tQptj0oKEiS7N6Zf+yxx3T8+HHNmzdP//73vyVJ1apV09y5c3XnnXe6JjAAAADgIoYr83l5eTKbzcW2X5smc/ny5VLP9fLy0m233abIyEj17t1bBQUFWrlypZ555hktWrRI4eHh5c5Tq5Zfuc8BAMAdgoL83R3BsHjvUFkZrsz7+PgoPz+/2PZrJd7e3Pd//OMf2rdvn1avXi0Pj6szjO655x7169dPL7/8spYvX17uPGfP5qiw0Fru8wAAfzzuLoQZGRfcOv71cvf7Jhn3vYPxeXiY7N48Ntyc+aCgoBKn0mRkZEiSateuXeJ5FotFq1ev1t13311U5CXJbDara9eu2rdvn65cueKa0AAAAIALGK7Mh4WF6ejRo8rNzbXZvnfv3qL9JcnKytKVK1dUUFBQbN+VK1d05coVWa3cYQcAAIBxGK7MR0ZGKj8/3+YhTxaLRYmJiYqIiCj6cGx6erqOHDlSdEytWrVUvXp1ffLJJzbTdHJzc/XZZ58pNDS0xLn4AAAAQGVluDnzrVq1UmRkpGJjY5WRkaHg4GAlJSUpPT1d06dPLzouJiZGO3fu1KFDhyRJnp6eGj9+vOLi4jRy5EgNGDBAhYWFWr16tX755RfFxMS46yUBAAAA18VwZV6SZsyYobi4OCUnJys7O1tNmjTRggUL1LZtW7vnPf7446pXr56WLFmiOXPmyGKxqEmTJpo9e7Z69+5dQekBAAAA5zBZmSh+Q1jNBgDgqKAgfw1O+MwtYycN7W7YFVmCgvy1ILH058i42sQhtQ373sH4fner2QAAAAC4ijIPAAAAGBRlHgAAADAoyjwAAABgUJR5AAAAwKAo8wAAAIBBUeYBAAAAgzLkQ6MAAO7jH+AjH7PZLWPn5efrQlaeW8YGgMqIMg/AZWoEmOVl9nHL2Jb8PGVn5btl7N87H7NZ/RLeccvYa4c+rAuizAPANZR5AC7jZfbRSyv6umXs/xu5QRJlHgDw+8aceQAAAMCgKPMAAACAQVHmAQAAAINyeM780aNHtXPnTqWlpSkzM1Mmk0mBgYEKDQ1V+/bt1aBBA1fmBAAAAPAbdsv85cuXlZCQoBUrVuj777+X1Wot8TiTyaTQ0FCNGjVKQ4YMkbe3t0vCAgAAAPifUsv8Bx98oLi4OJ06dUrt2rXTpEmT1KZNGwUHBysgIEBWq1XZ2dk6duyYvv32W23ZskXTpk3T/PnzNWnSJA0cOLAiXwcAAPIPqCofs/sWasvLv6ILWZfcNj6AP55S/8T729/+plGjRmns2LGqW7duicf4+PioTp066tChgyZOnKiffvpJixcv1l//+lfKPACgwvmYq6j/6gS3jb9m2FBdcNvoAP6ISi3zmzZt0k033VSui9WtW1d/+ctfNGHChBsOBgAAAMC+UlezKW+R/7WgoKDrPhcAAACAY1iaEgAAADAop5X5zz77TFOnTnXW5QAAAACUwWll/uDBg/rggw+cdTkAAAAAZWCaDQAAAGBQdhfjjYqKcvhC6enpNxwGAAAAgOPslvmdO3eqSpUqMpvNZV7oypUrTgsFAK7mH+AlH7P7nladl39ZF7IsbhsfAPD7YLfM16lTR02bNtW8efPKvNDcuXM1a9YspwUDAFfyMXvrnuTRbhv/44Hv64Io8wCAG2N3znyzZs20f/9+hy5kMpmcEggAAACAY+yW+ebNm+vMmTM6depUmRfy9/fXLbfc4rRgAAAAAOyzW+bHjx+vzZs3KzAwsMwLjRkzRp9++qnTggEAAACwz+6c+WrVqqlatWoVlQUAAABAObDOPAAAAGBQlHkAAADAoK6rzJ87d05NmzbV9u3bnZ0HAAAAgIOu+8681Wp1Zg4AAAAA5WT3A7AAAACwLyDAV2aze2Yu5+cXKisr1y1jo3KgzAMAANwAs9lDny7LcMvYPR4Icsu4qDwcKvPp6ek2X2dnZ0uSMjMzi+279dZbnRQNAAAAgD0OlfkePXrIZDIV2z558uRi21JTU288FQAAAIAyOVTmX375ZZsyn5ubq5deeknjx49Xo0aNXBYOAAAAQOkcKvNDhgyx+frcuXN66aWX1KVLF3Xq1MklwQAAAADYx0OjAAAAAIMyZJm3WCx67bXX1KVLF4WHh2vEiBHleoDVmjVrNGzYMLVu3VodOnTQmDFjlJKS4sLEAAAAgPMZcmnKKVOmaOPGjYqKilJISIiSkpI0YcIExcfHq02bNnbPnTlzpt5++20NGDBAI0eO1MWLF3Xw4EFlZLhnSSkAAADgel1Xmff399eSJUvUtGlTZ+cpU0pKitatW6epU6dq3LhxkqRBgwapX79+io2N1bJly0o995tvvtH8+fM1a9Ys9e7du4ISAwAAAK5xXdNsqlSpog4dOsjf39/Zecq0fv16mc1mDR8+vGibt7e3hg0bpt27d+v06dOlnrtkyRK1bNlSvXv3VmFhoXJzeWIaAAAAjMtwc+ZTU1PVoEED+fr62mwPDw+X1Wq1u8799u3b1bJlS73xxhtq27atIiIi1KNHD3344Yeujg0AAAA4neHmzGdkZKhOnTrFtgcFXX2ccWl35rOzs5WVlaV169bJ09NTkydPVkBAgJYtW6bnnntOVatWZeoNAAAADMVwZT4vL09ms7nYdm9vb0nS5cuXSzzv4sWLkqSsrCytXLlSrVq1kiT17t1bvXv31pw5c66rzNeq5VfucwBUjKCgip8KWB6VPV9lVdnft8qcrzJnq+wq83tXmbPB9QxX5n18fJSfn19s+7USf63U/9a17fXq1Ssq8pLk5eWlvn37asmSJcrNzS02facsZ8/mqLDQWq5zgD8Kd/8Fk5FxodR97s4m2c9Xmbn7vTPy99Xd+fg1d/34vsJdPDxMdm8eG27OfFBQUIlTaa4tLVm7du0SzwsICJCXl5duuummYvtuuukmWa1W5eTkODcsAAAA4EKGK/NhYWE6evRosZVo9u7dW7S/JB4eHmratKlOnTpVbN8vv/wiT09P1ahRw/mBAQAAABe57jKfmZmpzMxMZ2ZxSGRkpPLz87Vq1aqibRaLRYmJiYqIiCj6cGx6erqOHDlS7Nyff/5ZW7duLdqWk5Ojjz/+WG3atJGPj0/FvAgAAADACco1Z/7UqVN64403tHnz5qI7435+furZs6cmTZpU4iozztaqVStFRkYqNjZWGRkZCg4OVlJSktLT0zV9+vSi42JiYrRz504dOnSoaNvo0aO1atUqPfXUUxo3bpyqV6+uhIQEXbhwQc8++6zLswMAAADO5HCZT09P14gRI3TmzBk1bdpUjRo1kiQdOXJEH3zwgbZu3aqVK1fqlltucVnYa2bMmKG4uDglJycrOztbTZo00YIFC9S2bVu751WtWlVLlizRjBkztHTpUuXl5al58+ZauHBhmecCAAAAlY3DZf7NN9/U+fPnNX/+fHXr1s1m3+eff66nnnpKb775pl555RWnh/wtb29vxcTEKCYmptRj4uPjS9weFBSk1157zVXRAAAAgArjcJnfunWr7r///mJFXpK6deum0aNHa+3atU4NBwAAgN+vmjWqydPL0y1jF1gKlJl90S1jO5PDZT47O1shISGl7g8JCdH58+edEgoAAFQs/4Bq8jG7p1RJUl5+gS5kGb9YoXw8vTz1yxvfuWXsm59t7pZxnc3hMn/zzTdr586dGj16dIn7v/76a918881OCwYAACqOj9lTIxO+d9v4K4aGikcfAeXn8NKUkZGRWr9+vV5//XVduPC/3245OTl644039PHHH+vee+91SUgAAAAAxTl8Z/6JJ57Q119/rbfeekvvvvtu0ZNWT58+rYKCAkVEROjxxx93WVAAAAAAthwu81WrVlV8fLwSExO1adMmnTx5UpLUpUsX9erVS4MHD1aVKuVath4AAADADShX+65SpYpGjBihESNGuCoPAAAAAAc5PGc+KipK27dvL3X/V199paioKKeEAgAAAFA2h8v8zp07debMmVL3Z2ZmateuXU4JBQAAAKBsDpf5spw/f15eXl7OuhwAAACAMtidM3/w4EEdPHiw6Ouvv/5aBQUFxY7LysrS+++/r4YNGzo/IQAAAIAS2S3zmzZt0uzZsyVJJpNJK1as0IoVK0o81tfXV88//7zzEwIAAAAokd0yP3jwYHXo0EFWq1UPPvigHn30Ud155502x5hMJlWrVk2NGjWSt7e3S8MCAAAA+B+7Zb5u3bqqW7euJGn69Olq37696tWrVyHBAAAAANjn8DrzgwcPdmUOAAAAAOXktNVsAAAAAFQsyjwAAABgUJR5AAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAbltDKfnJysqKgoZ10OAAAAQBmcVubT09O1a9cuZ10OAAAAQBmYZgMAAAAYlN0nwPbs2dPhC+Xk5NxwGAAAAACOs1vmf/rpJ9WoUUO1a9cu80J5eXlOCwUAAACgbHbLfL169RQSEqJ33nmnzAvNnTtXs2bNclowAAAAAPbZLfPNmzfXjh07HLqQyWRySiD8MQXW8FIVL2+3jH3Fclnnsi1uGRsoiX+Aj3zMZreNn5efrwtZ/NOLntkAACAASURBVGsrABiB3TLfrFkzbdiwQSdPnlS9evXsXujWW29Vu3btnBoOfxxVvLy1Z15/t4zd5rE1kijzqDx8zGbdm/Sq28b/aHCMLogyDwBGYHc1m0cffVQHDx4ss8hL0sCBAxUfH++0YAAAAADsY2lKAAAAwKCuu8wXFhYqPT1dFgvTEwAAAAB3uO4yn5mZqZ49e2r37t3OzAMAAADAQTc0zcZqtTorBwAAAIByYs48AAAAYFCUeQAAAMCgrrvM+/j4aPDgwapdu7Yz8wAAAABwkN2HRtnj5+en6dOnOzMLAAAAgHJgmg0AAABgUKWW+fvvv1+7du0q9wW3b9+u0aNH31AoAAAAAGUrdZpN7dq1NXbsWDVr1kyDBg3SXXfdpdtuu63EYw8fPqzPP/9cycnJSktL07333uuqvAAAAAD+q9QyHxcXp927d2vu3LmaPn26pk+frurVq6tu3boKCAiQ1WpVdna2jh8/rtzcXJlMJnXp0kXTpk1T69atXRraYrHozTffVHJyss6fP6+wsDBNmjRJnTp1Ktd1JkyYoC1btigqKkrPP/+8i9ICAAAArmH3A7Bt27bVO++8o+PHj2v9+vXatWuXjhw5oh9++EEmk0mBgYFq166dOnTooD59+qhevXoVEnrKlCnauHGjoqKiFBISoqSkJE2YMEHx8fFq06aNQ9f4z3/+o6+//trFSQEAAADXcWg1m+DgYE2cOFETJ050dZ4ypaSkaN26dZo6darGjRsnSRo0aJD69eun2NhYLVu2rMxrWCwWTZ8+XQ8//LBmzZrl4sQAAACAa1z30pTusn79epnNZg0fPrxom7e3t4YNG6aZM2fq9OnTZa59v2TJEuXl5VHm4ZCAGl4ye3m7Zex8y2VlZVvcMjYAAKj8DFfmU1NT1aBBA/n6+tpsDw8Pl9VqVWpqqt0yn5GRoblz5+rFF19U1apVXR0XvwNmL2999I57PtR978MfSaLMAwCAkhlunfmMjIwSy3pQUJAk6fTp03bPf+ONN9SgQQMNHDjQJfkAAACAimK4O/N5eXkym83Ftnt7X50Gcfny5VLPTUlJ0QcffKD4+HiZTCan5KlVy88p14F7BQX5uztCqSpztsqusr93lTkf2a5fZc5XmbNJlTsf2X6ffg/vneHKvI+Pj/Lz84ttv1bir5X637JarfrnP/+pPn36qF27dk7Lc/ZsjgoLrU673h+Vu38zZWRcKHVfZc5W2VXm987d2aTS81XmbJL781XmbFLlzleZs0n8nrhe/D1x/Yzw3nl4mOzePDZcmQ8KCipxKk1GRoYklTpf/pNPPlFKSoomTZqkkydP2uzLycnRyZMnddNNN8nHx8f5oQEAAAAXMFyZDwsLU3x8vHJzc20+BLt3796i/SVJT09XYWGhHnzwwWL7EhMTlZiYqLfeekt33XWXa4IDAAAATlauMl9QUKA1a9boyy+/1NmzZ/Xcc8+pWbNmys7O1meffaZOnTqpTp06rsoqSYqMjNS7776rVatWFa0zb7FYlJiYqIiIiKLx09PTdenSJTVs2FCS1KNHjxIfavXkk0+qe/fuGjZsmJo3b+7S7AAAAIAzOVzmL126pPHjx2vPnj2qWrWq8vLylJ2dLUny8/NTbGyshg4dqkmTJrksrCS1atVKkZGRio2NVUZGhoKDg5WUlKT09HRNnz696LiYmBjt3LlThw4dknT1wVfBwcElXrN+/frq1auXS3MDAABUtMAavqri5b7FC69YCnUuO9dt4/8ROFzmZ82apf3792v27NmKiIhQ586di/Z5enqqT58++vLLL11e5iVpxowZiouLU3JysrKzs9WkSRMtWLBAbdu2dfnYAAAARlHFy0Nps0+5bfzG0a6dsYFylPn169dr5MiR6tWrl86dO1dsf3BwsD766COnhiuNt7e3YmJiFBMTU+ox8fHxDl3r2p17AAAAwGgc/neX06dPq0mTJqXur1q1qnJz+WcUAAAAoKI4XOYDAgJ06lTp/0yTlpZW6rKQAAAAAJzP4TLfqVMnJSYm6tKlS8X2nThxQgkJCeratatTwwEAAAAoncNlPjo6WufPn9ewYcP0/vvvy2Qy6YsvvtDrr7+uIUOGyMvLS48++qgrswIAAAD4FYfLfEhIiBYtWiRPT0/961//ktVq1bvvvqu33npLN998sxYvXqxbbrnFlVkBAAAA/Eq5HhrVokULffjhh/r+++915MgRWa1W3XbbbWrWrJmr8gEAAAAohUNlPjc3VwMHDtSYMWM0btw4hYaGKjQ01NXZAAAAANjh0DQbX19fZWVlydfX19V5AAAAADjI4TnzrVq10r59+1yZBQAAAEA5OFzmJ0+erPXr1yshIUFWq9WVmQAAAAA4wOEPwE6fPl3Vq1fX//3f/+m1115TcHCwfHx8bI4xmUxavHix00MCAAAAKM7hMn/y5ElJKlp+8syZM65JBAAAAMAhDpf5Tz/91JU5AAAAAJSTw3PmAQAAAFQu5XpolCTl5ORo27ZtOnHihCSpfv366ty5s/z8/JweDgAAAEDpylXmV61apVdeeUUXL14sWtHGZDKpWrVqmjJlioYPH+6SkAAAAACKc7jMb968WS+88ILq16+vp59+Wo0bN5YkpaWlaenSpXrxxRdVq1Yt9ejRw2VhAQAAAPyPw2X+7bffVsOGDbVy5UqbJ8F26tRJQ4YM0ciRI/XWW29R5gEAAIAK4vAHYA8ePKjBgwfbFPlr/Pz8NGjQIB08eNCp4QAAAACUzmmr2ZhMJmddCgAAAIADHC7zTZo0UVJSki5evFhsX25urpKSkhQWFubUcAAAAABK5/Cc+UceeUTR0dEaPHiwoqKi1LBhQ0nS4cOHFR8fr+PHj2vWrFkuCwoAAADAlsNlvlevXnrhhRcUGxurf/zjH0XTaqxWq6pWraoXXnhBvXr1cllQAAAAALbKtc78Aw88oP79+2vr1q06efKkpKsPjbrzzjvl7+/vkoAAAAAASlbuJ8BWr15d99xzjyuyAAAAACgHhz8Ae+DAAS1btqzU/cuWLVNqaqpTQgEAAAAom8Nlfvbs2frPf/5T6v4tW7Zozpw5zsgEAAAAwAEOl/l9+/apffv2pe5v3769UlJSnBIKAAAAQNkcLvPnzp1TQEBAqfurV6+uc+fOOSUUAAAAgLI5XOZr1aqltLS0Uvd///33qlGjhlNCAQAAACibw2W+c+fOWr16dYmF/vDhw0pISFDnzp2dGg4AAABA6RxemvLxxx/Xxo0bNWzYMA0dOlRNmzaVJKWmpiohIUFms1lPPPGEy4ICAAAAsOVwmQ8ODtaiRYs0depUvffeezb7GjdurJdfflm33Xabs/MBAAAAKEW5HhrVsmVLrV27Vqmpqfrxxx8lSQ0aNFBYWJgrsgEAAACwo9xPgJWkpk2bFk2zAeA+NQLM8jL7uG18S36esrPy3TY+AAB/dNdV5iXpxIkTWrdunU6dOqVGjRpp6NCh8vFxX6kA/oi8zD56d3Eft40//sGNkijzAAC4i90yv2rVKsXHx2vhwoWqVatW0fatW7cqOjpaeXl5slqtMplMWr58uZYvXy5fX1+XhwYAAABQxtKU//nPf+Tr62tT5K1Wq1588UXl5eVp4sSJ+ve//63BgwcrLS1NixYtcnVeAAAAAP9l9878wYMHdc8999hs++abb/TTTz9p0KBBmjRpkiSpe/fu+umnn7R582Y9+eSTrksLAAAAoIjdO/OZmZmqX7++zbZvvvlGJpOpWMnv1q2bjh075vyEAAAAAEpkt8xXqVJF+fm2H27bt2+fJKl169Y22wMCAmSxWJwcDwAAAEBp7Jb5unXras+ePUVfFxQUaPfu3QoJCVGNGjVsjs3KylJgYKBrUgIAAAAoxu6c+T59+mju3Llq06aN7rjjDiUkJCgzM1NDhw4tdmxKSorq1avnsqC/ZrFY9Oabbyo5OVnnz59XWFiYJk2apE6dOtk9b+PGjfroo4+UkpKis2fP6pZbblH37t31xBNPyN/fv0KyAwAAAM5it8xHRUUpOTlZ//znPyVdXcnmlltu0UMPPWRz3IULF/T5559r3LhxLgv6a1OmTNHGjRsVFRWlkJAQJSUlacKECYqPj1ebNm1KPe+FF15Q7dq1NXDgQN166606dOiQ4uPj9cUXXyghIUHe3t4Vkh8AAABwBrtl3s/PTwkJCVq5cqWOHTum4OBgDR8+XNWrV7c57siRIxoyZIjuu+8+l4aVrv4LwLp16zR16tSiHx4GDRqkfv36KTY2VsuWLSv13H/961/q2LGjzbYWLVooJiZG69at05AhQ1wZHQAAAHCqMp8A6+fnp/Hjx9s9pnXr1sU+EOsq69evl9ls1vDhw4u2eXt7a9iwYZo5c6ZOnz6t2rVrl3jub4u8JPXq1UvS1R9IAAAAACOx+wHYyig1NVUNGjQo9qTZ8PBwWa1Wpaamlut6Z86ckSQ+vAsAAADDMVyZz8jIKPHOe1BQkCTp9OnT5breW2+9JU9PT/Xp08cp+QAAAICKUuY0m8omLy9PZrO52PZrH169fPmyw9das2aNVq9erUcffVTBwcHXladWLb/rOg+VS1BQ5V3NqDJnkyp3vsqcTarc+ch2/SpzvsqcTarc+ch2/SpzvsqczVGGK/M+Pj7FHmQl/a/EO7oizddff63nn39ed999t55++unrznP2bI4KC63XfT6ucvdvpoyMC6XuI5t9lTlfZc4mlZ6vMmeT3J+vMmeTKne+ypxN4vfE9arM2aTKnc9etsrCw8Nk9+ax4abZBAUFlTiVJiMjQ5JK/fDrrx08eFCPP/64mjRpopkzZ8rT09PpOQEAAABXM1yZDwsL09GjR5Wbm2uzfe/evUX77Tl+/LgeeeQR1axZU/Pnz1e1atVclhUAAABwJbtlvqCgQLGxsXr//fftXuS9997TG2+8IavV9dNNIiMjlZ+fr1WrVhVts1gsSkxMVEREhOrUqSNJSk9PL7bcZEZGhsaPHy+TyaR33nlHNWvWdHleAAAAwFXszpn/8MMP9c4779gU55KEh4frH//4hxo3bqz+/fs7NeBvtWrVSpGRkYqNjVVGRoaCg4OVlJSk9PR0TZ8+vei4mJgY7dy5U4cOHSra9sgjj+jEiRN65JFHtHv3bu3evbtoX3BwsN2nxwIAAACVjd0y//HHH6tz585q0aKF3Yu0aNFCXbp00bp161xe5iVpxowZiouLU3JysrKzs9WkSRMtWLBAbdu2tXvewYMHJUlvv/12sX2DBw+mzAMAAMBQ7Jb57777Tg899JBDF+rYsaMWLVrkjExl8vb2VkxMjGJiYko9Jj4+vti2X9+lBwAAAIzO7pz57Oxs1apVy6EL1axZU1lZWU4JBQAAAKBsdsu8r6+vzp0759CFsrKy5Ovr65RQAAAAAMpmt8w3atRIW7dudehCW7duVaNGjZwSCgAAAEDZ7Jb53r17a9u2bdq0aZPdi2zevFnbtm1Tnz59nBoOAAAAQOnslvlRo0YpODhYzzzzjGbOnKmTJ0/a7D958qRmzpypZ555RrfddptGjRrl0rAAAAAA/sfuajY+Pj5asGCBHn30Uc2fP18LFiyQn5+ffH19lZubq5ycHFmtVjVo0EDz58+Xt7d3ReUGAAAA/vDslnlJCgkJUXJyslauXKkNGzYoLS1NZ86cka+vr9q1a6c+ffpo+PDh8vHxqYi8AAAAAP6rzDIvXV3XfezYsRo7dqyr8wAAAABwkN0585J08eJF5ebm2j0mNzdXFy9edFooAAAAAGWzW+Z/+OEHdejQQfPnz7d7kQULFqhDhw46fvy4U8MBAAAAKJ3dMr98+XIFBgYqOjra7kWeeOIJ1axZU++//75TwwEAAAAond0yv337dvXt21deXl52L+Lt7a3IyEiHHzAFAAAA4MbZLfMnT55U48aNHbpQw4YNdeLECaeEAgAAAFA2u2W+sLBQHh5lfkb26oU8PFRYWOiUUAAAAADKZrepBwUF6fDhww5d6PDhwwoKCnJKKAAAAABls1vm27Vrp7Vr1zq0NOXatWvVvn17p4YDAAAAUDq7Zf6BBx5QZmamoqOjlZWVVeIx2dnZio6O1rlz5zRmzBiXhAQAAABQnN0nwLZs2VJPPvmkZs+erZ49e6pPnz5q0qSJ/Pz8lJubq9TUVG3atEk5OTl66qmn1Lx584rKDQAAAPzh2S3zkhQdHa2bb75ZcXFxSkpKkiSZTCZZrVZJ0k033aSpU6dq6NChrk0KAAAAwEaZZV6Shg0bpoEDB+qbb75RWlqacnJy5Ofnp8aNGysiIkJms9nVOQEAAAD8hkNlXpLMZrM6duyojh07ujIPAAAAAAc5tog8AAAAgErH7p35qKiocl3MZDJp8eLFNxQIAAAAgGPslvmdO3eqSpUqDs+JN5lMTgkFAAAAoGx2y3yVKld3d+7cWUOGDFH37t3l4cHMHAAAAKAysNvMt2zZomeffVbHjx9XdHS07rrrLr322mv64YcfKiofAAAAgFLYLfM1a9bU+PHjtWbNGq1YsUI9evTQypUrdd9992nkyJFatWqVcnNzKyorAAAAgF9xeM5MeHi4pk2bpi+//FKvvvqqqlatqhdffFFdunRRcnKyKzMCAAAAKIHD68xf4+3trQEDBqhu3bry8PDQtm3bdOLECVdkAwAAAGBHucr86dOn9cEHHygxMVHHjh1T7dq19eijj2ro0KGuygcAAACgFGWW+fz8fG3evFmJiYnaunWrPDw81KNHD02dOlVdu3ZldRsAAADATeyW+Zdeeklr1qzR+fPnFRoaqpiYGA0YMEABAQEVlQ8AAABAKeyW+aVLl8rHx0f33XefmjdvroKCAiUlJZV6vMlk0rhx45ydEQAAAEAJypxmk5eXp7Vr12rt2rVlXuyPXuZr1vCRp5djT8t1tgJLvjKz89wyNgAAANzDbplfsmRJReX4XfD0Mivj30vdMnbQ42MkUeYBAAD+SOyW+Q4dOlRUDgAAAADlxFI0AAAAgEFR5gEAAACDoswDAAAABkWZBwAAAAyKMg8AAAAYlCHLvMVi0WuvvaYuXbooPDxcI0aM0Pbt2x0699SpU3r66afVrl07RURE6IknntCJEydcnBgAAABwPkOW+SlTpmjx4sUaMGCAnn/+eXl4eGjChAnas2eP3fNyc3MVFRWl3bt367HHHtOf/vQnHThwQFFRUcrOzq6g9AAAAIBzlPkE2MomJSVF69at09SpU4ueNjto0CD169dPsbGxWrZsWannvvfeezp27JgSExPVrFkzSVLXrl3Vv39/LVq0SE8//XRFvAQAAADAKQx3Z379+vUym80aPnx40TZvb28NGzZMu3fv1unTp0s9d8OGDWrdunVRkZekhg0bqlOnTvr4449dmhsAAABwNsOV+dTUVDVo0EC+vr4228PDw2W1WpWamlrieYWFhTp06JBatGhRbF/Lli31448/6tKlSy7JDAAAALiC4cp8RkaGateuXWx7UFCQJJV6Zz4rK0sWi6XouN+ea7ValZGR4dywAAAAgAuZrFar1d0hyqNXr15q1KiR5s2bZ7P9xIkT6tWrl1544QWNGTOm2Hk///yz7r77bk2ZMkUPPfSQzb7Vq1fr+eef15o1axQaGnrd2axXCmSq4nnd59+Issa2XsmXqYq5AhOVb/zCKxZ5VPGqwESOj11wxSJPN2Ura+wrBRZV8XRPNkfGd2e+ssa2FFjk5cb3zt74loIr8vJ030eayhrfnfnKzlYgL0/3/DnsyPjuzFd2tkJ5ebrvHp+98a8UWFXF01TBiRwfv6DAKk835Str7MIrVnlUcd97V9b41iuFMlVxz687d47tTIb7AKyPj4/y8/OLbb98+bKkq/PnS3Jtu8ViKfVcHx+fcuc5ezZHhYWV/+ehoCB//Tz3ebeNf8sT/1RGxoUyjrpcIVmub2yyXf/4vHeVd3wAQGXn4WFSrVp+pe+vwCxOERQUVOJUmmtTZEqagiNJAQEB8vLyKnEqTUZGhkwmU4lTcAAAAIDKynBlPiwsTEePHlVubq7N9r179xbtL4mHh4dCQ0O1f//+YvtSUlIUEhKiqlWrOj8wAAAA4CKGK/ORkZHKz8/XqlWrirZZLBYlJiYqIiJCderUkSSlp6fryJEjNuf27dtX3377rQ4cOFC07YcfftBXX32lyMjIinkBAAAAgJMYbs58q1atFBkZqdjYWGVkZCg4OFhJSUlKT0/X9OnTi46LiYnRzp07dejQoaJt999/v1atWqWJEyfqoYcekqenpxYtWqSgoKCiB1ABAAAARmG4Mi9JM2bMUFxcnJKTk5Wdna0mTZpowYIFatu2rd3z/Pz8FB8fr5dffllz585VYWGhOnbsqOeff16BgYEVlB4AAABwDsMtTVnZsJqNYxxbzQYAAAC/9rtbzQYAAADAVZR5AAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUJR5AAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUJR5AAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUJR5AAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUCar1Wp1dwgjO3s2R4WFlf8trFnDW55eXm4bv8BiUWb2ZbeNDwAAYEQeHibVquVX6v4qFZgFbnS1SFOmAQAAfk+YZgMAAAAYFGUeAAAAMCjKPAAAAGBQlHkAAADAoCjzAAAAgEFR5gEAAACDMuTSlOfPn9drr72mTz75RHl5eQoPD9fUqVPVtGlTu+cVFhYqKSlJn3zyiVJTU5Wdna169eqpX79+Gj9+vLzcuA47AAAAUF6Ge2hUYWGh7r//fn3//fcaP368AgMD9d577+nUqVNKTExUcHBwqefm5uYqIiJCrVu31t13361atWppz549+uCDD9SxY0ctWrSo3HmM8tAoAAAAGE9ZD40yXJn/6KOPNGnSJM2ZM0e9evWSJGVmZqpv377q3r27ZsyYUeq5FotF+/fvV0REhM322bNna9asWVqyZIk6duxYrjyUeQAAALhKWWXecHPmN2zYoNq1a6tnz55F22rWrKl77rlHmzZtUn5+fqnnenl5FSvyktS7d29J0pEjR5wfGAAAAHARw5X51NRUNW/eXCaTyWZ7y5YtlZubq+PHj5f7mmfOnJEkBQYGOiUjAAAAUBEMV+YzMjJUu3btYtuvbTt9+nS5r/n222/L399fXbp0ueF8AAAAQEVx62o2hYWFdqfF/Jq3t7ckKS8vr8RVZ65ty8vLK1eGefPmadu2bZo2bZr8/f3Lda4ku3OYAAAAAFdya5nftWuXoqKiHDp2+/btqlmzpnx8fGSxWIrtv7bNx8fH4fE/+ugjxcXFaeTIkRo5cqTD5wEAAACVgVvL/O23367p06c7dKyf39U74EFBQSVOpbm2raQpOCXZunWr/vznP6t79+7661//6mBiAAAAoPJwa5kPCgrSkCFDynVOWFiY9uzZI6vVavMh2JSUFFWrVs3uOvPX7N27V9HR0WrZsqVmzpwpT0/PcmcHAAAA3M1wH4CNjIzU6dOntXnz5qJtmZmZWr9+vXr27Cmz2Vy0/fjx48VWtzly5IgmTpyounXrat68eeWalgMAAABUJoZ7aFRBQYHuv/9+paWlFT0B9v3339fPP/+sxMREhYSEFB3bo0cPSdKnn34qScrJyVG/fv106tQpTZo0SXXq1LG5dpMmTRQWFlZxLwYAAAC4AW6dZnM9PD09tWDBAs2YMUPx8fG6fPmyWrZsqVdffdWmyJckKytLP//8syTp9ddfL7Y/OjqaMg8AAADDMNydeQAAAABXGW7OPAAAAICrKPMAAACAQVHmAQAAAIOizAMAAAAGZbjVbH5PLBaL3nzzTSUnJ+v8+fMKCwvTpEmT1KlTJ3dH0+nTp7VkyRLt3btX+/fv18WLF7VkyRJ17NjR3dGUkpKipKQk7dixQ+np6QoICFCbNm30zDPPlLmiUUXYt2+f5s2bpwMHDujs2bPy9/dXWFiYnnzySUVERLg7XjFvvfWWYmNjFRYWpuTkZLfl2LFjh6Kiokrc99FHH6lhw4YVnKhkKSkpmj17tvbs2aMrV66ofv36GjduXLkfgOdMU6ZMUVJSUqn7t2zZUmwp3or2448/Ki4uTt98843Onz+vW2+9VYMGDdK4cePk5eXl1mzffvutZs6cqZSUFHl4eKhjx46aMmWKQw8hdKby/Lm7efNmzZ49W4cPH1atWrU0bNgwPfbYY6pSxTV/rTua7f3339dXX32llJQUpaena/DgwXrllVdckqk82c6dO6eEhAR9+umn+uGHH3TlyhU1bNhQ4/6/vXsPyynf/z/+TPo6psMIoxxipiiHyIS4zKaGNtNgHKIJjXZtxtiyHSaGzSWnPYONEu0G4zhOI6oxQ2LYmTJDCKUwbMdS0lkHtX5/+Hb/3ArNfKt1N96P63Jd1ue+7+5X6+pe632v9V6f5enJn//8Z9XzKYrCggULOHfuHPfv36ekpIRWrVoxcuRIxo4dq3UPnZrO9ry7d+8yePBgCgoKOHDgAB07dqyWbL8l34ABA7h7926513t7ezNz5kxVswHk5OSwbt06Dh8+TFpaGm+88Qb29vasWrWqSrJIMa8iPz8/jhw5wvjx42nTpg2hoaF4e3uzbds2unXrpmq2GzduEBISQps2bbC2tubcuXOq5nnWV199RVxcHC4uLlhbW5OWlsaOHTsYNmwY+/btU73ou337NiUlJYwaNQozMzNycnIIDw/Hw8ODkJAQ+vTpo2q+Z6WlpbF+UV0YhQAAFhVJREFU/XoaNmyodhSNCRMmYGtrqzWmdiFa5sSJE0yZMgUHBwemTZtG3bp1uXnzpmbKW7W4ubmVOwigKAoLFy7E3Nxc9fWXmprKqFGjMDQ0xMPDAyMjI86cOcPKlSu5evUqX375pWrZ4uPj8fDwwNzcnKlTp1JaWsrOnTtxd3fnwIEDNG3atMayVHa7W/Z32KtXL+bPn09ycjLr1q3j0aNHzJ8/X9VsISEh5Obm0rlzZ9LS0qoly+/Jdv78eVavXk2/fv2YPHkydevW5fDhw/j6+vLrr78yZcoUVfOVlpZy+fJl+vbti4WFBfr6+pw/f56lS5dy6dIlvvjiC9WyPe+f//wnderUTGPHb8lna2vLhAkTtMasrKxUz5adnc1HH31EdnY2o0aNokWLFqSlpfHLL79UXRhFqOLChQuKlZWVsnnzZs1YQUGB4uzsrLi7u6sX7H/l5OQoGRkZiqIoSmRkpGJlZaXExsaqnOqps2fPKoWFhVpjN27cUDp16qR89tlnKqV6ufz8fMXR0VHx8fFRO4qWzz77TBk3bpzi4eGhfPDBB6pmiY2NVaysrJTIyEhVc7xIdna20rt3b8Xf31/tKJXyyy+/KFZWVsr69evVjqIEBwcrVlZWSnJystb41KlTFRsbG6WoqEilZIri5eWlODg4KJmZmZqx1NRUxc7OTlm8eHGNZqnsdnfw4MHK8OHDlSdPnmjGVq1apXTo0EG5ceOGqtnu3LmjlJaWKoqiKPb29jWyTa5Mtlu3bil37tzRGistLVXGjx+vdOnSRXn8+LGq+V7E399fsba2Vh4+fKgT2WJjYxVbW1tl1apVipWVlZKQkFAtuX5rvv79+yuTJ0+u1iy/N9v8+fOVAQMGaJ5bHaRnXiU//PADBgYGjBo1SjNWr149Ro4cydmzZ3nw4IGK6aBx48aYmJiomuFFunfvXu60fNu2bXn77be5fv26SqlerkGDBpiampKdna12FI34+HjCwsKYM2eO2lHKyc3N5cmTJ2rH0BIeHk52djbTpk0DnmZUdPg2HREREejp6fH++++rHYW8vDwA3njjDa3xpk2bUrduXfT19dWIBUBcXBx9+/bFyMhIM9asWTMcHBz4/vvvazRLZba7165d49q1a7i5uWmtN3d3d0pLSzly5Ihq2QDMzc3R09OrlgwvUplsrVq1wtzcXGtMT08PZ2dnCgoKKmzRqMl8L9KyZUsURSEnJ6eKUz31W7KVlJSwZMkSPDw8aqyl9beuu6KiIh4/flyNif6/ymTLzs4mNDQULy8vTExMKCwspKioqMqzSDGvksTERCwtLWnUqJHWeJcuXVAUhcTERJWS1U6KopCenq5TX0Byc3PJyMjg119/ZdWqVSQnJ+vE9RDwdH35+/szbNiwau13/D1mzZqFvb09Xbt2ZeLEiSQlJakdCYCYmBjatWvHiRMnePfdd7G3t8fBwYEVK1ZQUlKidjwtxcXFfP/993Tr1g0LCwu14/DOO+8A8Pnnn3PlyhXu379PWFiYprWwpk7ZV6SoqIh69eqVG69fvz5paWmqH1h5XkJCAgCdOnXSGm/evDktWrTQPC4qJz09HUBn9h3FxcVkZGRw//59IiMj2bRpE61atdKJz/GuXbtITU3lk08+UTtKhU6dOoWdnR12dnY4Ozuze/dutSNx5swZioqKaNq0KZ6ennTt2hU7OzsmTpzIrVu3qux9pGdeJWlpaRX2sZqZmQHo3A5E14WFhZGamsr06dPVjqIxd+5cDh8+DICBgQFjxoxh0qRJKqd66sCBA1y7do1169apHUXDwMCAQYMG0a9fP0xMTEhKSmLTpk24u7uzb98+LC0tVc333//+l5SUFPz8/PjLX/6CjY0Nx48fJyQkhMLCQj7//HNV8z0rOjqazMxMXF1d1Y4CQN++fZk2bRrBwcEcO3ZMM/63v/2tWnuVK8PS0pLz589TWlqq+VJRVFREfHw88HRb3KxZMzUjainrQy/bVzzLzMxM9h2/QWZmJnv37sXBwQFTU1O14wBPP7vP7ic6derEsmXLVD17BU/X1dq1a5k6dSpNmjRRNUtFrKys6NGjB23btuXRo0fs2bOHf/zjH2RlZeHj46NarrKCff78+XTq1IlVq1bx4MEDAgMDmTBhAuHh4TRu3Pj//D5SzKukoKCgwqvTy44QFRYW1nSkWuv69essWrQIe3t7hg4dqnYcjSlTpuDm5kZKSgoHDx6kqKiI4uJi1WfuyM3NZeXKlfj4+OhUkdK9e3et2X6cnJwYMGAAI0aMIDAwkJUrV6qYDvLz88nKymLGjBmancPAgQPJz8/nm2++YfLkyTpTEERERGBgYFDts3T8FhYWFjg4OPDee+9hbGzMjz/+SEBAAKampowdO1a1XO7u7ixcuJB58+YxceJESktLWb9+vaZoLigoUC1bRcryVLQdqVevXo21GNR2paWlzJw5k5ycHObNm6d2HI2uXbuyefNmcnJyiI2NJTExkfz8fLVjsXbtWkxNTRkzZozaUSq0YcMGreUPP/wQd3d3goKCGDt2LIaGhqrkKmsxNDMzIyQkRHPAwNLSEh8fH7799ttyF+3+HtJmo5L69etTXFxcbrysiK/otK8oLy0tjb/+9a8YGRmxZs0aVU/XP8/a2po+ffowYsQINm7cyOXLl3WiP339+vUYGBjw8ccfqx3llTp06EDv3r2JjY1VOwr169cHKNeD7urqSnFxMRcvXlQjVjl5eXlERUXRt29fnWkd+O6771iwYAGLFy9m9OjRDBw4kKVLlzJ8+HC++OILsrKyVMs2duxYJk2aRFhYGEOGDMHV1ZVbt27h5eUFUK4VUm1lf4cV9d0WFhZqHhcv5+/vT3R0NMuWLcPa2lrtOBqmpqY4OjoyaNAgFixYgJOTEx9//HGNzQxUkeTkZHbt2oWfn1+1TX1a1fT19ZkwYQKPHz9WdTa+ss+ji4uLVn3y7rvvYmRkRFxcXJW8j+5UPq+ZF50OLfvA6tIRU12Vk5ODt7c3OTk5fPXVVxWedtYVBgYGODk5ceTIEVWP9D148IAtW7bg7u5Oeno6d+7c4c6dOxQWFlJcXMydO3dULawq8uabb+pEprK/r+enKixb1oWMAEePHuXx48c602IDsHPnTmxtbcu1Fg4YMID8/HyuXLmiUrKnpk+fzqlTp9ixYwdhYWF8++23KIqCnp4erVq1UjXb88r+Disq7tLS0mTfUQmBgYHs3LmTWbNm6cQF4i/j4uJCfn4+UVFRqmVYtWoVNjY2tG/fXrPPePToEfB0n6L21Lwv0qJFC0DdbfOL9htAlU6KUTu+Yv0BdejQgW3btpGXl6d15OfChQuax8WLFRYWMmnSJG7evMnXX39Nu3bt1I70SgUFBSiKQl5enmpHzx4+fEhxcTErVqxgxYoV5R53cnKq1pts/B63b9/WiSPMtra2/PTTT6SmpmoVeCkpKQA602ITHh5Ow4YNGTBggNpRNNLT0ytcP2VnJ3XhAmIjIyN69OihWf7pp5/o0qVLlfSzVqWyC9YvXbqkdT+G1NRUUlJSdO6Cdl2zY8cOAgIC8PT01Jx90WVlB3+qazabyrh//z5XrlzBycmp3GM+Pj40bdqUU6dOqZDs5W7fvg2ou20u+4ympqZqjZeWlpKWllbuniq/lxTzKnFxcWHTpk3s3bsXT09P4Olp0/3799O9e3fVb/Kiy0pKSvD19eX8+fMEBQVhZ2endiQtGRkZ5TYeubm5HD58mDfffLPc9Hw1ycLCosKLXlevXk1+fj5z586lbdu2NR+MitfbmTNnOH36NMOGDVMl07NcXFwICQlh3759mgutFUVh7969NGzYUCf+DjMyMoiJiWHIkCE0aNBA7TgalpaWnDp1ilu3bmndVfW7775DX19fp9oc4Okdhy9evFhld2esSm+//Tbt2rVj9+7djBw5UnNh5DfffEOdOnUYOHCgygl116FDh1i8eDGurq74+fmpHUdLZmYmhoaG5S503bt3L1B+9qKaNGfOHHJzc7XGYmNj2bZtG3PmzFH9YFpmZiZNmjTRamMpLCxk48aNNGrUSNVtc/v27bGysiI8PJxJkyZpWqgPHTpEbm5ulc1wJ8W8Srp27YqLiwsrVqwgLS2N1q1bExoayr1791i2bJna8QAICgoC0MzdfvDgQc6ePUuTJk3w8PBQLdfy5cs5duwY/fv3JzMzk4MHD2oea9SoEc7OzqplA/D19aVevXp069YNMzMz7t+/z/79+0lJSVG9ODA0NKxw/WzZsgV9fX1V152vry8NGjSgW7dumJiYcPXqVXbv3o2JiQlTp05VLVeZTp06MWzYMIKDg3n48CE2NjacOHGC6OhoZs2apRNHcA8dOsSTJ090qsUGwMvLi5MnTzJ27Fg++ugjjIyM+PHHHzl58iRjxoxR9QtuTEwMwcHB9OnTB2NjY86fP09oaCiurq4MGTKkxvNUZrs7e/ZsJk+ejJeXF4MHDyY5OZkdO3bg5uZWrbM+VSbbsWPHNG1TRUVFJCUlaV43dOjQcnO911S2+Ph4Zs+ejbGxMb179yYsLEzr9X369KnWu/2+Kt+xY8dYv3497733Hq1bt+bx48dER0cTHR3Nn/70p2qd1vhV2Xr16lXuNWXtIT179qz2s0GVWXcbNmxg0KBBmJubk5mZSWhoKDdv3mThwoXVet1LZT4Tfn5+eHt74+7uztChQ0lLS2PLli3Y2NjwwQcfVEkOPUWX73ryB1dYWMjq1asJDw8nKysLa2tr/v73v+Po6Kh2NIAXHi0zNzfXml6upo0bN46ff/65wsfUzgawb98+Dh48yLVr18jOzsbQ0FAzr6yDg4Oq2V5k3LhxZGdna30xqmlbt24lPDycW7dukZubi6mpKX379mXq1Km0bNlStVzPKioqIigoiAMHDpCeno6FhQWenp46M8ODm5sbt2/f5j//+Y/qU9k9Lz4+noCAABITE8nMzMTc3JwRI0bg5eWlatabN2+yaNEiEhISyMvLo23btowaNQoPDw9VLqiv7Hb36NGjBAYGcv36dUxNTRkxYgSffPJJtV6gWJlsfn5+hIaGVvi8rVu30rNnT1Wy7d+//6UTEFRnNnh1vuTkZIKDgzl37hzp6enUqVMHS0tLXF1dGTduXIWz39VUtoqUrc8DBw5UezH/qnyXLl0iMDCQhIQEMjIy+J//+R9sbW2ZOHEi/fv3VzVbmZMnTxIQEEBSUhINGzbEycmJmTNnVlkLqRTzQgghhBBC1FIym40QQgghhBC1lBTzQgghhBBC1FJSzAshhBBCCFFLSTEvhBBCCCFELSXFvBBCCCGEELWUFPNCCCGEEELUUlLMCyGEEEIIUUtJMS+EEEJVd+7cwdramoCAALWjCCFErSPFvBBC/MGdPn0aa2trrX+dO3fGycmJOXPmaG5F/nsFBARw9OjRKkpbdSIjI7G2tiY1NRWAQ4cO0aFDB82t6IUQ4o+g+u77LIQQQqe8//779OvXD4DCwkKSkpLYu3cvhw8fJjw8HHNz89/1cwMDAxk+fDjOzs5VGff/LC4uDgsLC5o3bw7A2bNneeutt2jSpInKyYQQoupIMS+EEK8JGxsbhg4dqjXWpk0blixZQmRkJJ6enuoEqybnzp2je/fumuWzZ8/SrVs3FRMJIUTVk2JeCCFeY82aNQPAwMBAa3zHjh1ERUVx9epVHj16hLGxMb169cLX1xcLCwvgaa+7k5MTAKGhoYSGhmpen5SUpPl/bGwsmzZt4sKFC+Tn59OsWTN69uzJzJkzMTU11Xrf48ePExgYSHJyMkZGRri6ujJjxgzq1n317qq4uJicnBwASkpKuHz5Mk5OTmRkZFBQUEBycjIffvghGRkZABgbG1OnjnSbCiFqNz1FURS1QwghhKg+p0+fZvz48UydOhV3d3fgaZtNcnIyS5cuJSsri/DwcMzMzDSvcXJyws7ODmtra4yNjUlOTmbfvn00btyY8PBwTExMyM/PJzIyktmzZ9OjRw9Gjx6teX3ZGYBdu3axcOFCmjdvzrBhwzA3N+fevXscP36c5cuX07FjR82Xgs6dO3P37l3GjBmDmZkZUVFRREdHM336dCZNmlTp37OyoqKiNF9MhBCitpJiXggh/uBeVuS+9dZbrF27lvbt22uN5+fn07BhQ62xmJgYPD09mTlzJt7e3ppxa2trhg8fzvLly7Wen5KSgrOzM61bt2bXrl3letVLS0upU6eOpphv0KABERERmgJbURRcXV3JzMwkOjr6lb9nVlYWly9fBmDPnj38/PPPrFixAoCdO3dy+fJllixZonm+vb099erVe+XPFUIIXSZtNkII8Zpwc3PDxcUFeHpk/tq1a2zevBkfHx+2bt2qdQFsWSFfWlpKXl4excXFWFtbY2hoSHx8fKXe74cffqC4uJhPP/20wotOn29xcXJy0jpSrqenR8+ePdm+fTt5eXk0atTope9nZGSEo6MjAGvWrMHR0VGz/OWXX9K3b1/NshBC/FFIMS+EEK+JNm3aaBWz/fv3x8HBgdGjR7NixQr+9a9/aR6LiYkhKCiICxcuUFhYqPVzsrKyKvV+N2/eBKBjx46Ven6rVq3KjRkbGwOQmZn50mL+2X75vLw8Ll68iKurKxkZGeTk5JCYmIi7u7umX/75Xn0hhKitpJgXQojXWNeuXTE0NCQ2NlYzFh8fj5eXF61bt2bGjBlYWFhQv3599PT0mD59OtXVnamvr//Cx171nnFxceVaifz9/fH399csz5s3j3nz5gHaF+gKIURtJsW8EEK85kpKSigqKtIsR0REUFJSQkhIiNbR8vz8/N90w6W2bdsCkJiYiKWlZZXlrUiHDh3YvHkzANu3byc5OZlFixYBsHHjRu7du8f8+fOrNYMQQqhB5uQSQojX2KlTp8jPz8fW1lYz9qIj5MHBwZSWlpYbb9iwIZmZmeXGXVxcMDAwYN26deTm5pZ7vCqP8Jf1yzs6OvLgwQN69eqlWU5JSdH8/9k+eiGE+COQI/NCCPGaSEhI4ODBgwAUFRVx7do19uzZg4GBAb6+vprnOTs78/XXX+Pt7Y2bmxsGBgacOnWKpKQkTExMyv1cOzs7YmJi+Pe//03Lli3R09NjyJAhtGjRgrlz57Jo0SJcXV0ZOnQo5ubmpKamEhUVxdKlSyvdT19Zubm5JCQk4OHhAUBGRgbXr1/n008/rdL3EUIIXSHFvBBCvCYiIiKIiIgAns4kY2xsTJ8+ffDx8aFLly6a59nb2xMQEEBQUBBr1qyhXr16ODo6sn37dk2R/KwFCxawaNEiNmzYQF5eHgBDhgwBwN3dndatW7Nx40a2bdtGUVERzZo1o3fv3rRo0aLKf8e4uDhKSkp45513gKd3fVUURbMshBB/NDLPvBBCCCGEELWU9MwLIYQQQghRS0kxL4QQQgghRC0lxbwQQgghhBC1lBTzQgghhBBC1FJSzAshhBBCCFFLSTEvhBBCCCFELSXFvBBCCCGEELWUFPNCCCGEEELUUlLMCyGEEEIIUUtJMS+EEEIIIUQt9f8ASBS98Vgk7c8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8039d3-558e-4007-acb8-782aeacb27ad"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXx0jPc4HUfZ"
      },
      "source": [
        "You can also look at the official leaderboard [here](https://gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "## Saving & Loading Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec4603e-6239-47d8-cdb9-cca443fad357"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-tjHkR7lc1I"
      },
      "source": [
        "Let's check out the file sizes, out of curiosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949f7187-a9a9-4192-a6ad-fd6a8f30d04f"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 427984K\n",
            "-rw-r--r-- 1 root root      1K Jan 14 11:21 config.json\n",
            "-rw-r--r-- 1 root root 427743K Jan 14 11:21 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Jan 14 11:21 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Jan 14 11:21 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Jan 14 11:21 vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr_bt2rFlgDn"
      },
      "source": [
        "The largest file is the model weights, at around 418 megabytes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7d68f0-1758-45bc-848a-c66cc86621a5"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 418M Jan 14 11:21 ./model_save/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzGKvOFAll_e"
      },
      "source": [
        "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trr-A-POC18_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e88844-c655-4494-8ff3-721681239cd4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "!cp -r ./model_save/ \"./drive/MyDrive/BERT/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vstijw85SZ"
      },
      "source": [
        "The following functions will load the model back from disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nskPzUM084zL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163db640-9f29-4cfe-e75a-9a3b462e2c8a"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "# https://github.com/alontalmor/pytorch-transformers/blob/master/README.md\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ddRJmXkphsj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}